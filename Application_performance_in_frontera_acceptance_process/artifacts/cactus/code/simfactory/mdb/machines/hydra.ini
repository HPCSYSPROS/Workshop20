[hydra]

# Machine description
nickname        = hydra
name            = Hydra
location        = RZG
description     = An IBM iDataPlex at the RZG
webpage         = http://www.rzg.mpg.de/services/computing/hydra
status          = production

# Access to this machine
hostname        = hydra.rzg.mpg.de
rsynccmd        = /usr/bin/rsync
aliaspattern    = ^(hydra\d\d)$

sshcmd          = ssh -oProxyCommand="ssh @USER@@gate.rzg.mpg.de -W %h:22"

  # You will need to type your RZG password twice, and ssh keys are
  # "not allowed".  Set sshcmd=ssh in defs.local.ini/[hydra] if you
  # only want to access Hydra from the Max Planck network, where going
  # through gate is not required, and reduce the number of password
  # prompts to one.

  # If you are on a private machine, you can customise the above
  # sshcmd in defs.local.ini by adding -oControlMaster=auto
  # -oControlPath=/tmp/%r@%h:%p to the end.  You then only need to use
  # "sim login" once, and as long as that connection is open, any
  # other accesses to this machine via simfactory will use the same
  # connection, so you won't need to type a password.

  # You can also use Kerberos tickets to authenticate to
  # gate.rzg.mpg.de and hydra01i.rzg.mpg.de allowing passwordless
  # logins without having to keep a connection open.
  # Use: kinit -f @USER@@IPP-GARCHING.MPG.DE
  # to create the initial kerberos ticket and
  # ssh @USER@@gate.rzg.mpg.de to log in. You need to enable
  # GSSAPIAuthentication and GSSAPIDelegateCredentials in your
  # ssh_config files.

envsetup        = source /etc/profile.d/modules.sh; module purge && module load intel/15.0 && module load mpi.ibm/1.3.0 && module load git

# Source tree management
sourcebasedir   = /u/@USER@
disabled-thorns = <<EOT
    CaCUDA/CaCUDALib
    CaCUDA/WaveToyCUDA
    CarpetExtra/Nirvana
    CarpetDev/CarpetIONirvana
    ExternalLibraries/CGNS
    ExternalLibraries/F5
    CarpetDev/CarpetIOF5
    ExternalLibraries/git
    ExternalLibraries/PETSc
    CactusElliptic/EllPETSc
    TAT/TATPETSc
    LSUDevelopment/WaveToyNoGhostsPETSc
EOT

# NoExcision gives an internal compiler error with Intel 15.0.0 in cg.f90

optionlist      = hydra.cfg
submitscript    = hydra.sub
runscript       = hydra.run
make            = nice make -j16

# Simulation management
basedir         = /ptmp/@USER@/simulations

# There are two classes of nodes: Sandy Bridge and Ivy Bridge. The
# settings below are for the Ivy Bridge nodes which are newer, faster,
# and much more numerous.  You can run on core-counts which are
# multiples of 20.  20-core jobs of 30 minutes or less run on a single
# node in a testing queue.  You CANNOT run core counts between 21 and
# 79 on these nodes.  Apart from the 20-core testing case, you must
# run on at least 80 cores, otherwise the queueing system will reject
# the job.

# If you want to run on fewer than 80 cores, you need to use the Sandy
# Bridge nodes.  To do this, specify --ppn=16 --num-threads=8 on your
# simfactory submission command line, and ask for a multiple of 16
# cores.

cpu             = Intel Xeon Ivy Bridge-EP (Xeon E5-2680v2)
cpufreq         = 2.8
flop/cycle      = 4
ppn             = 20
# spn             = 4864
# mpn             = 4864
max-num-threads = 40
num-threads     = 10
memory          = 65536
nodes           = 3500
min-ppn         = 1
allocation      = NO_ALLOCATION
maxwalltime     = 24:00:00
submit          = llsubmit @SCRIPTFILE@
getstatus       = llq @JOB_ID@
stop            = llcancel @JOB_ID@
submitpattern   = The job "(.*)" has been submitted\.
statuspattern   = ^@JOB_ID@[. ]
queuedpattern   = " I "
runningpattern  = " R "
holdingpattern  = " H "
scratchbasedir  = /dev/null
exechost        = llq -f '%h' @JOB_ID@b | tail +3 | head -1
exechostpattern = (.*)
stdout          = cat @SIMULATION_NAME@.out
stderr          = cat @SIMULATION_NAME@.err
stdout-follow   = false   # don't know
